{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2739456,"sourceType":"datasetVersion","datasetId":1670098},{"sourceId":8998346,"sourceType":"datasetVersion","datasetId":5418758},{"sourceId":9016773,"sourceType":"datasetVersion","datasetId":5419947},{"sourceId":9048087,"sourceType":"datasetVersion","datasetId":5430105},{"sourceId":9048758,"sourceType":"datasetVersion","datasetId":5400149},{"sourceId":9054926,"sourceType":"datasetVersion","datasetId":5456557}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":15287.310374,"end_time":"2024-07-20T20:10:46.061757","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-07-20T15:55:58.751383","version":"2.5.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"def add_to_class(Class):\n    def wrapper(obj):\n        setattr(Class, obj.__name__, obj)\n    return wrapper","metadata":{"papermill":{"duration":0.027118,"end_time":"2024-07-20T15:56:01.819252","exception":false,"start_time":"2024-07-20T15:56:01.792134","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T09:33:24.828961Z","iopub.execute_input":"2024-08-02T09:33:24.829409Z","iopub.status.idle":"2024-08-02T09:33:24.868642Z","shell.execute_reply.started":"2024-08-02T09:33:24.829369Z","shell.execute_reply":"2024-08-02T09:33:24.867290Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from typing import Optional, Callable, List, Tuple\n\nimport torch\nfrom torch import nn\nimport torchaudio\nimport librosa\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport math\n\nimport re\nimport os\n\nimport IPython.display as ipd","metadata":{"papermill":{"duration":6.157554,"end_time":"2024-07-20T15:56:07.983639","exception":false,"start_time":"2024-07-20T15:56:01.826085","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T09:33:24.871232Z","iopub.execute_input":"2024-08-02T09:33:24.871749Z","iopub.status.idle":"2024-08-02T09:33:30.736933Z","shell.execute_reply.started":"2024-08-02T09:33:24.871714Z","shell.execute_reply":"2024-08-02T09:33:30.735404Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/s4t-update')\nimport S4T as S","metadata":{"execution":{"iopub.status.busy":"2024-08-02T09:33:30.738469Z","iopub.execute_input":"2024-08-02T09:33:30.738983Z","iopub.status.idle":"2024-08-02T09:33:30.758506Z","shell.execute_reply.started":"2024-08-02T09:33:30.738949Z","shell.execute_reply":"2024-08-02T09:33:30.757171Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"sys.path.append('/kaggle/input/asr-helper')\n\nfrom Conformer import ConformerEncoderLayer, ConformerEncoder\nfrom Transformer import CustomTransformerDecoderLayer, CustomTransformerDecoder\nfrom RNNT import _TimeReduction\nfrom Tokenizer import BPETokenizer\nfrom Embedding import PositionalEncodding","metadata":{"papermill":{"duration":0.071012,"end_time":"2024-07-20T15:56:08.061381","exception":false,"start_time":"2024-07-20T15:56:07.990369","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T09:33:30.763255Z","iopub.execute_input":"2024-08-02T09:33:30.763754Z","iopub.status.idle":"2024-08-02T09:33:30.819122Z","shell.execute_reply.started":"2024-08-02T09:33:30.763714Z","shell.execute_reply":"2024-08-02T09:33:30.817900Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"papermill":{"duration":0.098653,"end_time":"2024-07-20T15:56:08.166547","exception":false,"start_time":"2024-07-20T15:56:08.067894","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T09:33:30.820714Z","iopub.execute_input":"2024-08-02T09:33:30.821121Z","iopub.status.idle":"2024-08-02T09:33:30.831084Z","shell.execute_reply.started":"2024-08-02T09:33:30.821086Z","shell.execute_reply":"2024-08-02T09:33:30.829018Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'cpu'"},"metadata":{}}]},{"cell_type":"markdown","source":"## LibriSpeech100","metadata":{"papermill":{"duration":0.006411,"end_time":"2024-07-20T15:56:08.179456","exception":false,"start_time":"2024-07-20T15:56:08.173045","status":"completed"},"tags":[]}},{"cell_type":"code","source":"TRANSFORM = nn.Sequential(torchaudio.transforms.MelSpectrogram(sample_rate = 16000,\n                                                                 n_fft = 512,\n                                                                 win_length = 400,\n                                                                 hop_length = 160,\n                                                                 n_mels = 80),\n                          torchaudio.transforms.AmplitudeToDB())\nTRAIN_TRANSFORM = torchaudio.transforms.SpecAugment(n_time_masks = 10,\n                                      time_mask_param = 10,\n                                      n_freq_masks = 1,\n                                      freq_mask_param = 27)","metadata":{"papermill":{"duration":0.166317,"end_time":"2024-07-20T15:56:08.352084","exception":false,"start_time":"2024-07-20T15:56:08.185767","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T09:33:30.833196Z","iopub.execute_input":"2024-08-02T09:33:30.833964Z","iopub.status.idle":"2024-08-02T09:33:30.967264Z","shell.execute_reply.started":"2024-08-02T09:33:30.833925Z","shell.execute_reply":"2024-08-02T09:33:30.965665Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#\nPAD_IDX = 0\nUNK_IDX = 1\nBOS_IDX = 2\nEOS_IDX = 3","metadata":{"papermill":{"duration":0.013123,"end_time":"2024-07-20T15:56:08.371834","exception":false,"start_time":"2024-07-20T15:56:08.358711","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T09:33:30.968988Z","iopub.execute_input":"2024-08-02T09:33:30.969586Z","iopub.status.idle":"2024-08-02T09:33:30.979088Z","shell.execute_reply.started":"2024-08-02T09:33:30.969534Z","shell.execute_reply":"2024-08-02T09:33:30.976670Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class VectorizeChar:\n    def __init__(self):\n        self.vocab = (\n            [\"-\", \"#\", \"<\", \">\"]\n            + [chr(i + 96) for i in range(1, 27)]\n            + [\" \", \"'\"]\n        )\n        self.char_to_idx = {}\n        for i, ch in enumerate(self.vocab):\n            self.char_to_idx[ch] = i\n\n    def __call__(self, text):\n        text = text.lower()\n        text = \"<\" + text + \">\"\n        encoded = []\n        return [self.char_to_idx.get(ch, 1) for ch in text]\n\n    def get_vocabulary(self):\n        return self.vocab\n    \n    def itos(self, indices):\n        chars = []\n        for idx in indices:\n            chars.append(self.vocab[idx])\n        text = \"\".join(chars).replace(\"<\", \"\").replace(\">\",\"\")\n        return text","metadata":{"execution":{"iopub.status.busy":"2024-08-02T09:47:55.723849Z","iopub.execute_input":"2024-08-02T09:47:55.724242Z","iopub.status.idle":"2024-08-02T09:47:55.735197Z","shell.execute_reply.started":"2024-08-02T09:47:55.724213Z","shell.execute_reply":"2024-08-02T09:47:55.733800Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"class LibriSpeech100(torch.utils.data.Dataset):\n    def __init__(self, root, subset = 'train'):\n        super().__init__()\n        self.subset = subset\n        self.dataset = torchaudio.datasets.LIBRISPEECH(root, url = subset)\n\n    def __getitem__(self, idx):\n        wav, _, text, *_ = self.dataset[idx]\n        wav = TRANSFORM(wav)\n        if 'train' in self.subset:\n            wav = TRAIN_TRANSFORM(wav)\n        return wav, text\n\n    def __len__(self):\n        return len(self.dataset)","metadata":{"papermill":{"duration":0.015208,"end_time":"2024-07-20T15:56:08.393357","exception":false,"start_time":"2024-07-20T15:56:08.378149","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T09:47:57.147318Z","iopub.execute_input":"2024-08-02T09:47:57.147732Z","iopub.status.idle":"2024-08-02T09:47:57.156598Z","shell.execute_reply.started":"2024-08-02T09:47:57.147699Z","shell.execute_reply":"2024-08-02T09:47:57.155426Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"class LS100(S.SDataModule):\n    def __init__(self, root, batch_size):\n        super().__init__()\n        self.root = root\n        self.batch_size = batch_size\n        train100 = LibriSpeech100(root,\n                                 subset = 'train-clean-100')\n        train360 = LibriSpeech100(root,\n                                 subset = 'train-clean-360')\n        self.train_dataset = torch.utils.data.ConcatDataset([train100, train360])\n        # self.train_dataset = train100\n        self.val_dataset = LibriSpeech100(root,\n                               subset = 'dev-clean')\n        self.test_dataset = LibriSpeech100(root,\n                                subset = 'test-clean')\n        self.tokenizer = VectorizeChar()\n\n    def train_dataloader(self):\n        return torch.utils.data.DataLoader(self.train_dataset,\n                                           batch_size = self.batch_size,\n                                           shuffle = True,\n                                           collate_fn = self.collate_fn,\n                                           num_workers = 3,\n                                           prefetch_factor = 1,\n                                           pin_memory = True,\n                                           drop_last = False)\n\n    def val_dataloader(self):\n        return torch.utils.data.DataLoader(self.val_dataset,\n                                           batch_size = self.batch_size,\n                                           shuffle = False,\n                                           collate_fn = self.collate_fn,\n                                           num_workers = 3,\n                                           prefetch_factor = 1,\n                                           pin_memory = True)\n\n    def test_dataloader(self):\n        return torch.utils.data.DataLoader(self.test_dataset,\n                                           batch_size = 1,\n                                           shuffle = False,\n                                           collate_fn = self.collate_fn,\n                                           num_workers = 1,\n                                           prefetch_factor = 1,\n                                           pin_memory = True)\n\n    def collate_fn(self, batch):\n        src_batch, src_lengths, tgt_batch = [], [], []\n        for src_sample, tgt_sample in batch:\n            tgt_sample = torch.tensor(self.tokenizer(tgt_sample.lower()))\n            src_batch.append(src_sample.squeeze(0).transpose(0, 1).contiguous())\n            tgt_batch.append(tgt_sample)\n            src_lengths.append(src_sample.shape[2])\n\n        src_batch = nn.utils.rnn.pad_sequence(src_batch, batch_first = True, padding_value = 0)\n        tgt_batch = nn.utils.rnn.pad_sequence(tgt_batch, batch_first = True, padding_value = PAD_IDX)\n        src_lengths = torch.tensor(src_lengths)\n        return src_batch, tgt_batch.type(torch.long), src_lengths.type(torch.long)","metadata":{"papermill":{"duration":0.022918,"end_time":"2024-07-20T15:56:08.422677","exception":false,"start_time":"2024-07-20T15:56:08.399759","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T09:47:57.404317Z","iopub.execute_input":"2024-08-02T09:47:57.404757Z","iopub.status.idle":"2024-08-02T09:47:57.423571Z","shell.execute_reply.started":"2024-08-02T09:47:57.404723Z","shell.execute_reply":"2024-08-02T09:47:57.421930Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"data = LS100('/kaggle/input/librispeech-clean', 16)","metadata":{"papermill":{"duration":44.926202,"end_time":"2024-07-20T15:56:53.356152","exception":false,"start_time":"2024-07-20T15:56:08.429950","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T09:47:57.750210Z","iopub.execute_input":"2024-08-02T09:47:57.750966Z","iopub.status.idle":"2024-08-02T09:48:01.667573Z","shell.execute_reply.started":"2024-08-02T09:47:57.750928Z","shell.execute_reply":"2024-08-02T09:48:01.666312Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{"papermill":{"duration":0.006265,"end_time":"2024-07-20T15:56:53.369301","exception":false,"start_time":"2024-07-20T15:56:53.363036","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class _ConformerEncoder(nn.Module):\n    def __init__(self,\n                 input_dim: int,\n                 output_dim: int,\n                 time_reduction_stride: int,\n                 conformer_input_dim: int,\n                 conformer_ffn_dim: int,\n                 conformer_num_layers: int,\n                 conformer_num_heads: int,\n                 conformer_depthwise_conv_kernel_size: int,\n                 conformer_dropout: float) -> None:\n        super().__init__()\n        self.time_reduction = _TimeReduction(time_reduction_stride)\n        self.input_linear = nn.Linear(input_dim*time_reduction_stride, conformer_input_dim)\n        conformerencoderlayer = ConformerEncoderLayer(input_dim = conformer_input_dim,\n                                                      ffn_dim = conformer_ffn_dim,\n                                                      num_heads = conformer_num_heads,\n                                                      kernel_size = conformer_depthwise_conv_kernel_size,\n                                                      dropout = conformer_dropout)\n        self.conformer = ConformerEncoder(conformerencoderlayer,\n                                          num_layers = conformer_num_layers)\n        self.output_linear = nn.Linear(conformer_input_dim, output_dim)\n        self.layer_norm = nn.LayerNorm(output_dim)\n\n    def forward(self,\n                input: torch.Tensor,\n                lengths: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        input: (N, T, D)\n        length: (N,)\n        \"\"\"\n        time_reduction_out, time_reduction_lengths = self.time_reduction(input, lengths)\n        input_linear_out = self.input_linear(time_reduction_out)\n        x, _, key_padding_mask = self.conformer(input_linear_out, time_reduction_lengths)\n        output_linear_out = self.output_linear(x)\n        layer_norm_out = self.layer_norm(output_linear_out)\n        return layer_norm_out, key_padding_mask","metadata":{"papermill":{"duration":0.019916,"end_time":"2024-07-20T15:56:53.395507","exception":false,"start_time":"2024-07-20T15:56:53.375591","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T09:34:08.261878Z","iopub.execute_input":"2024-08-02T09:34:08.262384Z","iopub.status.idle":"2024-08-02T09:34:08.276993Z","shell.execute_reply.started":"2024-08-02T09:34:08.262320Z","shell.execute_reply":"2024-08-02T09:34:08.275402Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):  #@save\n    \"\"\"Positional encoding.\"\"\"\n    def __init__(self, num_hiddens, dropout, max_len=1000):\n        super().__init__()\n        self.dropout = nn.Dropout(dropout)\n        # Create a long enough P\n        self.P = torch.zeros((1, max_len, num_hiddens))\n        X = torch.arange(max_len, dtype=torch.float32).reshape(\n            -1, 1) / torch.pow(10000, torch.arange(\n            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n        self.P[:, :, 0::2] = torch.sin(X)\n        self.P[:, :, 1::2] = torch.cos(X)\n\n    def forward(self, X):\n        X = X + self.P[:, :X.shape[1], :].to(X.device)\n        return self.dropout(X)\n\nclass TokenEmbedding(nn.Module):\n    def __init__(self, vocab_size, emb_size):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, emb_size)\n        self.emb_size = emb_size\n\n    def forward(self, tokens):\n        return self.embedding(tokens.long())*math.sqrt(self.emb_size)\n\ndef generate_square_subsequent_mask(sz):\n    mask = (torch.triu(torch.ones((sz, sz))) == 1).transpose(0, 1)\n    mask = mask.masked_fill(mask == 0, True).masked_fill(mask == 1, False).type(torch.bool)\n    return mask\n\ndef create_tgt_mask(tgt):\n    tgt_seq_len = tgt.shape[1]\n\n    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n\n    tgt_padding_mask = (tgt == PAD_IDX)\n    return tgt_mask.to(tgt.device), tgt_padding_mask.to(tgt.device)\n\nclass _TransformerDecoder(nn.Module):\n    def __init__(self,\n                 vocab_size: int,\n                 num_hiddens: int,\n                 ffn_num_hiddens: int,\n                 num_heads: int,\n                 num_blks: int,\n                 dropout = 0.1):\n        super().__init__()\n        self.num_hiddens = num_hiddens\n        self.vocab_size = vocab_size\n        self.tgt_tok_emb = TokenEmbedding(vocab_size, num_hiddens)\n        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n        decoder_layer = CustomTransformerDecoderLayer(d_model = num_hiddens,\n                                                      n_head = num_heads,\n                                                      dim_feedforward = ffn_num_hiddens,\n                                                      dropout = dropout,\n                                                      rel_attn = False)\n        self.transformer_decoder = CustomTransformerDecoder(decoder_layer, num_blks)\n\n    def forward(self,\n                tgt: torch.Tensor,\n                memory: torch.Tensor,\n                tgt_mask: Optional[torch.Tensor] = None,\n                tgt_key_padding_mask: Optional[torch.Tensor] = None,\n                memory_key_padding_mask: Optional[torch.Tensor] = None):\n        tgt_emb = self.pos_encoding(self.tgt_tok_emb(tgt))\n        # tgt_emb = self.tgt_tok_emb(tgt)\n        return self.transformer_decoder(tgt_emb, memory, tgt_mask, tgt_key_padding_mask,\n                                        memory_key_padding_mask)","metadata":{"papermill":{"duration":0.022109,"end_time":"2024-07-20T15:56:53.424047","exception":false,"start_time":"2024-07-20T15:56:53.401938","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T09:34:08.279273Z","iopub.execute_input":"2024-08-02T09:34:08.279762Z","iopub.status.idle":"2024-08-02T09:34:08.305712Z","shell.execute_reply.started":"2024-08-02T09:34:08.279719Z","shell.execute_reply":"2024-08-02T09:34:08.304322Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class ConformerAED(nn.Module):\n    def __init__(self,\n                 input_dim: int,\n                 time_reduction_stride: int,\n                 conformer_input_dim: int,\n                 conformer_output_dim: int,\n                 conformer_ffn_dim: int,\n                 conformer_num_layers: int,\n                 conformer_num_heads: int,\n                 conformer_depthwise_conv_kernel_size: int,\n                 conformer_dropout: float,\n                 vocab_size: int,\n                 decoder_input_dim: int,\n                 decoder_ffn_dim: int,\n                 decoder_num_layers: int,\n                 decoder_num_heads: int,\n                 decoder_dropout: float) -> None:\n        super().__init__()\n        self.conformer_output_dim = conformer_output_dim\n        self.decoder_input_dim = decoder_input_dim\n        self.encoder = _ConformerEncoder(input_dim,\n                                         conformer_output_dim,\n                                         time_reduction_stride,\n                                         conformer_input_dim,\n                                         conformer_ffn_dim,\n                                         conformer_num_layers,\n                                         conformer_num_heads,\n                                         conformer_depthwise_conv_kernel_size,\n                                         conformer_dropout)\n        self.decoder = _TransformerDecoder(vocab_size,\n                                           decoder_input_dim,\n                                           decoder_ffn_dim,\n                                           decoder_num_heads,\n                                           decoder_num_layers,\n                                           decoder_dropout)\n        if conformer_output_dim != decoder_input_dim:\n            self.cross_linear = nn.Linear(conformer_output_dim, decoder_input_dim)\n        self.classifier = nn.Linear(decoder_input_dim, vocab_size)\n\n    def forward(self,\n                src: torch.Tensor,\n                tgt: torch.Tensor,\n                src_lengths: Optional[torch.Tensor] = None,\n                tgt_mask: Optional[torch.Tensor] = None,\n                tgt_padding_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n        \"\"\"\n\n        src: shape (N, Ts, F)\n        tgt: shape (N, Tt)\n        \"\"\"\n        memory, memory_key_padding_mask  = self.encoder(src,\n                                                            src_lengths)\n        if self.conformer_output_dim != self.decoder_input_dim:\n            memory = self.cross_linear(memory)\n        outs = self.decoder(tgt, memory,\n                            tgt_mask = tgt_mask,\n                            tgt_key_padding_mask = tgt_padding_mask,\n                            memory_key_padding_mask = memory_key_padding_mask)\n        return self.classifier(outs)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T09:34:08.307163Z","iopub.execute_input":"2024-08-02T09:34:08.307623Z","iopub.status.idle":"2024-08-02T09:34:08.328197Z","shell.execute_reply.started":"2024-08-02T09:34:08.307577Z","shell.execute_reply":"2024-08-02T09:34:08.326852Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"@add_to_class(ConformerAED)\ndef generate(self,\n             src: torch.Tensor,\n             src_lengths: Optional[torch.Tensor],\n             max_tgt_lengths: int = 400,\n             start_symbol: int = 0):\n    memory, memory_key_padding_mask = self.encoder(src, src_lengths)\n    if self.conformer_output_dim != self.decoder_input_dim:\n        memory = self.cross_linear(memory)\n    dec_input = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(src)\n    dec_logits = []\n    for i in range(max_tgt_lengths-1):\n        tgt_mask = generate_square_subsequent_mask(dec_input.shape[1])\n        out = self.decoder(dec_input, memory, tgt_mask, memory_key_padding_mask = memory_key_padding_mask)\n        out = out.transpose(1, 2).contiguous()\n        prob = self.classifier(out[:, :, -1])\n        _, next_word = torch.max(prob, dim = -1)\n        dec_logits.append(next_word.item())\n        \n        dec_input = torch.cat([dec_input, torch.ones(1, 1).type_as(src.data).fill_(next_word.item())], dim = 1)\n        if next_word == EOS_IDX:\n            break\n    return dec_logits","metadata":{"execution":{"iopub.status.busy":"2024-08-02T09:52:48.777439Z","iopub.execute_input":"2024-08-02T09:52:48.777878Z","iopub.status.idle":"2024-08-02T09:52:48.789655Z","shell.execute_reply.started":"2024-08-02T09:52:48.777844Z","shell.execute_reply":"2024-08-02T09:52:48.788410Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"### Pipelining","metadata":{"papermill":{"duration":0.006514,"end_time":"2024-07-20T15:56:53.438119","exception":false,"start_time":"2024-07-20T15:56:53.431605","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class ConformerAED_training(S.SModule, ConformerAED):\n    def __init__(self,\n                 lr: Optional[Callable] = 0.0001,\n                 *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n        self.lr = lr","metadata":{"papermill":{"duration":0.023881,"end_time":"2024-07-20T15:56:53.468318","exception":false,"start_time":"2024-07-20T15:56:53.444437","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-02T09:50:42.327527Z","iopub.execute_input":"2024-08-02T09:50:42.327958Z","iopub.status.idle":"2024-08-02T09:50:42.334623Z","shell.execute_reply.started":"2024-08-02T09:50:42.327926Z","shell.execute_reply":"2024-08-02T09:50:42.333358Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"@add_to_class(ConformerAED_training)\ndef loss(self, y_hat, y):\n    return nn.functional.cross_entropy(y_hat, y,\n                                       ignore_index = PAD_IDX,\n                                       reduction = 'mean',\n                                       label_smoothing = 0.1)\n\n@add_to_class(ConformerAED_training)\ndef training_step(self, batch, batch_idx):\n    src, tgt, src_lengths = batch\n    dec_input = tgt[:, :-1]\n    dec_target = tgt[:, 1:]\n\n    tgt_mask, tgt_padding_mask = create_tgt_mask(dec_input)\n    preds = self.forward(src, dec_input,\n                         src_lengths = src_lengths,\n                         tgt_mask = tgt_mask,\n                         tgt_padding_mask = tgt_padding_mask)\n    del dec_input\n    del src\n    del tgt\n    \n    loss = self.loss(preds.reshape(-1, preds.shape[-1]), dec_target.reshape(-1))\n    self.log(\"train_loss\", loss, pbar = True, train_logging = True)\n    return loss\n\n@add_to_class(ConformerAED_training)\ndef validation_step(self, batch, batch_idx):\n    src, tgt, src_lengths = batch\n    dec_input = tgt[:, :-1]\n    dec_target = tgt[:, 1:]\n\n    tgt_mask, tgt_padding_mask = create_tgt_mask(dec_input)\n    preds = self.forward(src, dec_input,\n                         src_lengths = src_lengths,\n                         tgt_mask = tgt_mask,\n                         tgt_padding_mask = tgt_padding_mask)\n    del dec_input\n    del src\n    del tgt\n    \n    loss = self.loss(preds.reshape(-1, preds.shape[-1]), dec_target.reshape(-1))\n    self.log(\"val_loss\", loss, pbar = True, train_logging = False)\n\n@add_to_class(ConformerAED_training)\ndef configure_optimizers(self):\n    optimizer = torch.optim.Adam(self.parameters(), lr = 0.0005,\n                                 weight_decay = 1e-6,\n                                 betas = (0.9, 0.98),\n                                 eps = 1e-9)\n    return optimizer\n\n@add_to_class(ConformerAED_training)\ndef optimizer_step(self, epoch, batch_idx, optimizer, optimizer_closure):\n    # update params\n    optimizer.step(closure = optimizer_closure)\n\n    # manually warm up lr without a scheduler\n    lr = self.lr.calculate_lr(epoch)\n\n    for pg in optimizer.param_groups:\n        pg['lr'] = lr\n    self.log('lr', lr, pbar = True, train_logging = True)","metadata":{"papermill":{"duration":0.020934,"end_time":"2024-07-20T15:56:53.495487","exception":false,"start_time":"2024-07-20T15:56:53.474553","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-07-28T11:24:40.392769Z","iopub.execute_input":"2024-07-28T11:24:40.393040Z","iopub.status.idle":"2024-07-28T11:24:40.406104Z","shell.execute_reply.started":"2024-07-28T11:24:40.393017Z","shell.execute_reply":"2024-07-28T11:24:40.405355Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"@add_to_class(ConformerAED_training)\ndef apply_init(self):\n    for p in self.parameters():\n        if p.dim() > 1:\n            nn.init.xavier_uniform_(p)","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:24:40.407140Z","iopub.execute_input":"2024-07-28T11:24:40.407427Z","iopub.status.idle":"2024-07-28T11:24:40.418272Z","shell.execute_reply.started":"2024-07-28T11:24:40.407404Z","shell.execute_reply":"2024-07-28T11:24:40.417515Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class CustomLRScheduler:\n    def __init__(self,\n                 init_lr = 0.0005,\n                 lr_after_warmup = 0.001,\n                 final_lr = 0.0001,\n                 warmup_epochs = 5,\n                 decay_epochs = 100):\n        self.init_lr = init_lr\n        self.lr_after_warmup = lr_after_warmup\n        self.final_lr = final_lr\n        self.warmup_epochs = warmup_epochs\n        self.decay_epochs = decay_epochs\n\n    def calculate_lr(self, epoch):\n        \"\"\"\n        Linear warm up - linear decay\n        \"\"\"\n        warmup_lr = self.init_lr + ((self.lr_after_warmup - self.init_lr)/(self.warmup_epochs - 1))*epoch\n        decay_lr = max(self.final_lr,\n                       self.lr_after_warmup\n                       - (epoch - self.warmup_epochs)\n                       *(self.lr_after_warmup - self.final_lr)\n                       /self.decay_epochs)\n        return min(warmup_lr, decay_lr)","metadata":{"papermill":{"duration":0.016057,"end_time":"2024-07-20T15:56:53.517865","exception":false,"start_time":"2024-07-20T15:56:53.501808","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-07-28T11:24:40.419472Z","iopub.execute_input":"2024-07-28T11:24:40.420092Z","iopub.status.idle":"2024-07-28T11:24:40.427759Z","shell.execute_reply.started":"2024-07-28T11:24:40.420061Z","shell.execute_reply":"2024-07-28T11:24:40.426919Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"checkpoint_callback = S.ModelCheckpoint(dirpath = '/kaggle/working',\n                                      save_top_k = 7, monitor = 'val_loss',\n                                      mode = 'min',\n                                      filename = 'conformer_aed-char-ls100-epoch:%02d-val_loss:%.4f')","metadata":{"papermill":{"duration":0.012883,"end_time":"2024-07-20T15:56:53.537422","exception":false,"start_time":"2024-07-20T15:56:53.524539","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-07-28T11:24:40.428796Z","iopub.execute_input":"2024-07-28T11:24:40.429376Z","iopub.status.idle":"2024-07-28T11:24:40.435969Z","shell.execute_reply.started":"2024-07-28T11:24:40.429318Z","shell.execute_reply":"2024-07-28T11:24:40.435168Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"lr = CustomLRScheduler()\nmodel = ConformerAED_training(input_dim = 80,\n                                     time_reduction_stride = 4,\n                                     conformer_input_dim = 512,\n                                     conformer_output_dim = 512,\n                                     conformer_ffn_dim = 512,\n                                     conformer_num_layers = 4,\n                                     conformer_num_heads = 4,\n                                     conformer_depthwise_conv_kernel_size = 31,\n                                     conformer_dropout = 0.1,\n                                     vocab_size = len(data.tokenizer.vocab),\n                                     decoder_input_dim = 512,\n                                     decoder_ffn_dim = 512,\n                                     decoder_num_layers = 4,\n                                     decoder_num_heads = 4,\n                                     decoder_dropout = 0.1,\n                             lr = lr)\nmodel.apply_init()","metadata":{"papermill":{"duration":0.461972,"end_time":"2024-07-20T15:56:54.005696","exception":false,"start_time":"2024-07-20T15:56:53.543724","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-07-28T11:24:40.438442Z","iopub.execute_input":"2024-07-28T11:24:40.438770Z","iopub.status.idle":"2024-07-28T11:24:40.838532Z","shell.execute_reply.started":"2024-07-28T11:24:40.438740Z","shell.execute_reply":"2024-07-28T11:24:40.837716Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(pytorch_total_params)","metadata":{"papermill":{"duration":0.016676,"end_time":"2024-07-20T15:56:54.029082","exception":false,"start_time":"2024-07-20T15:56:54.012406","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-07-28T11:24:40.839709Z","iopub.execute_input":"2024-07-28T11:24:40.840053Z","iopub.status.idle":"2024-07-28T11:24:40.847507Z","shell.execute_reply.started":"2024-07-28T11:24:40.840021Z","shell.execute_reply":"2024-07-28T11:24:40.846638Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"23672864\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = S.Trainer(callbacks = [checkpoint_callback],\n                   enable_checkpointing = True,\n                   max_epochs = 40,\n                   gradient_clip_val = 1,\n                   accelerator = 'gpu')\ntrainer.fit(model, data, ckpt_path = '/kaggle/input/rel-char/conformer_aed-char-ls100-epoch_19-val_loss_1.3056.ckpt')","metadata":{"papermill":{"duration":15216.104295,"end_time":"2024-07-20T20:10:30.139790","exception":false,"start_time":"2024-07-20T15:56:54.035495","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-07-28T11:24:44.472366Z","iopub.execute_input":"2024-07-28T11:24:44.473319Z","iopub.status.idle":"2024-07-28T11:57:11.137482Z","shell.execute_reply.started":"2024-07-28T11:24:44.473258Z","shell.execute_reply":"2024-07-28T11:57:11.136324Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":">> Epoch 0/1: validating... 168/169 [===================>] - 0.15s/step - val_loss: 2.0664in_loss: 1.8713","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"defaultdict(list,\n            {'lr': [0.0005000000000000512],\n             'train_loss': [2.0868028508803897],\n             'val_loss': [1.8482922555426875]})"},"metadata":{}}]},{"cell_type":"code","source":"print('!Done')","metadata":{"papermill":{"duration":4.155446,"end_time":"2024-07-20T20:10:38.428937","exception":false,"start_time":"2024-07-20T20:10:34.273491","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"model = ConformerAED_training(input_dim = 80,\n                                     time_reduction_stride = 4,\n                                     conformer_input_dim = 512,\n                                     conformer_output_dim = 512,\n                                     conformer_ffn_dim = 512,\n                                     conformer_num_layers = 4,\n                                     conformer_num_heads = 4,\n                                     conformer_depthwise_conv_kernel_size = 31,\n                                     conformer_dropout = 0.1,\n                                     vocab_size = len(data.tokenizer.vocab),\n                                     decoder_input_dim = 512,\n                                     decoder_ffn_dim = 512,\n                                     decoder_num_layers = 4,\n                                     decoder_num_heads = 4,\n                                     decoder_dropout = 0.1,\n                             lr = 0.001)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T09:50:51.758707Z","iopub.execute_input":"2024-08-02T09:50:51.759111Z","iopub.status.idle":"2024-08-02T09:50:51.987721Z","shell.execute_reply.started":"2024-08-02T09:50:51.759078Z","shell.execute_reply":"2024-08-02T09:50:51.986339Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"ckpt_path = '/kaggle/input/rel-char/conformer_aed-char-ls100-epoch_36-val_loss_1.1421.ckpt'\nckpt = torch.load(ckpt_path, map_location = device)\nmodel.load_state_dict(ckpt['state_dict'])","metadata":{"execution":{"iopub.status.busy":"2024-08-02T09:50:51.989725Z","iopub.execute_input":"2024-08-02T09:50:51.990103Z","iopub.status.idle":"2024-08-02T09:50:52.137235Z","shell.execute_reply.started":"2024-08-02T09:50:51.990070Z","shell.execute_reply":"2024-08-02T09:50:52.136102Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"def transcribe(model: Callable,\n               tokenizer: Callable,\n               src: torch.Tensor,\n               src_lengths: Optional[torch.Tensor] = None,\n               max_tgt_lengths: int = 400):\n    model.eval()\n    tgt_tokens = model.generate(src, src_lengths, max_tgt_lengths, BOS_IDX)\n    return tokenizer.itos(tgt_tokens)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T09:53:10.955870Z","iopub.execute_input":"2024-08-02T09:53:10.956289Z","iopub.status.idle":"2024-08-02T09:53:10.964182Z","shell.execute_reply.started":"2024-08-02T09:53:10.956258Z","shell.execute_reply":"2024-08-02T09:53:10.962468Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"test_dataset = LibriSpeech100('/kaggle/input/librispeech-clean',\n                              subset = 'test-clean')\nspec0, text0 = test_dataset[0]\nspec0 = spec0.transpose(1, 2).contiguous()\nprint(spec0.shape)\nprint(text0)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T09:53:11.128766Z","iopub.execute_input":"2024-08-02T09:53:11.129174Z","iopub.status.idle":"2024-08-02T09:53:11.253306Z","shell.execute_reply.started":"2024-08-02T09:53:11.129141Z","shell.execute_reply":"2024-08-02T09:53:11.252376Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"torch.Size([1, 1044, 80])\nHE HOPED THERE WOULD BE STEW FOR DINNER TURNIPS AND CARROTS AND BRUISED POTATOES AND FAT MUTTON PIECES TO BE LADLED OUT IN THICK PEPPERED FLOUR FATTENED SAUCE\n","output_type":"stream"}]},{"cell_type":"code","source":"transcribe(model, data.tokenizer, spec0, torch.tensor([spec0.shape[1]]), 400)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T09:53:12.181987Z","iopub.execute_input":"2024-08-02T09:53:12.182407Z","iopub.status.idle":"2024-08-02T09:53:21.998019Z","shell.execute_reply.started":"2024-08-02T09:53:12.182375Z","shell.execute_reply":"2024-08-02T09:53:21.996650Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"'he laid allowed that these do be would be stue for the inner turnips and carriage sent broose potatoes and facf mutton pieces to be lattle doubten sauces to be lattened sauces'"},"metadata":{}}]},{"cell_type":"code","source":"spec0, text0 = test_dataset[1]\nspec0 = spec0.transpose(1, 2).contiguous()\nprint(spec0.shape)\nprint(text0)\ntranscribe(model, data.tokenizer, spec0, torch.tensor([spec0.shape[1]]), 400)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T09:54:01.327257Z","iopub.execute_input":"2024-08-02T09:54:01.328201Z","iopub.status.idle":"2024-08-02T09:54:02.359245Z","shell.execute_reply.started":"2024-08-02T09:54:01.328158Z","shell.execute_reply":"2024-08-02T09:54:02.357705Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"torch.Size([1, 328, 80])\nSTUFF IT INTO YOU HIS BELLY COUNSELLED HIM\n","output_type":"stream"},{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"'stuffed how to him'"},"metadata":{}}]},{"cell_type":"code","source":"spec0, text0 = test_dataset[2]\nspec0 = spec0.transpose(1, 2).contiguous()\nprint(spec0.shape)\nprint(text0)\ntranscribe(model, data.tokenizer, spec0, torch.tensor([spec0.shape[1]]), 400)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T09:54:30.953897Z","iopub.execute_input":"2024-08-02T09:54:30.954323Z","iopub.status.idle":"2024-08-02T09:54:32.417995Z","shell.execute_reply.started":"2024-08-02T09:54:30.954290Z","shell.execute_reply":"2024-08-02T09:54:32.416753Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"torch.Size([1, 663, 80])\nAFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"'after the prophels'"},"metadata":{}}]},{"cell_type":"code","source":"spec0, text0 = test_dataset[3]\nspec0 = spec0.transpose(1, 2).contiguous()\nprint(spec0.shape)\nprint(text0)\ntranscribe(model, data.tokenizer, spec0, torch.tensor([spec0.shape[1]]), 400)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T09:55:07.447664Z","iopub.execute_input":"2024-08-02T09:55:07.448167Z","iopub.status.idle":"2024-08-02T09:55:08.654792Z","shell.execute_reply.started":"2024-08-02T09:55:07.448122Z","shell.execute_reply":"2024-08-02T09:55:08.653181Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"torch.Size([1, 269, 80])\nHELLO BERTIE ANY GOOD IN YOUR MIND\n","output_type":"stream"},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"'how a burty and you go in her mind'"},"metadata":{}}]},{"cell_type":"code","source":"spec0, text0 = test_dataset[5]\nspec0 = spec0.transpose(1, 2).contiguous()\nprint(spec0.shape)\nprint(text0)\ntranscribe(model, data.tokenizer, spec0, torch.tensor([spec0.shape[1]]), 400)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T09:55:27.170891Z","iopub.execute_input":"2024-08-02T09:55:27.171430Z","iopub.status.idle":"2024-08-02T09:55:29.174771Z","shell.execute_reply.started":"2024-08-02T09:55:27.171387Z","shell.execute_reply":"2024-08-02T09:55:29.173258Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"torch.Size([1, 964, 80])\nTHE MUSIC CAME NEARER AND HE RECALLED THE WORDS THE WORDS OF SHELLEY'S FRAGMENT UPON THE MOON WANDERING COMPANIONLESS PALE FOR WEARINESS\n","output_type":"stream"},{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"'the warriorious'"},"metadata":{}}]},{"cell_type":"code","source":"spec0, text0 = data.train_dataset[4]\nspec0 = spec0.transpose(1, 2).contiguous()\nprint(spec0.shape)\nprint(text0)\ntranscribe(model, data.tokenizer, spec0, torch.tensor([spec0.shape[1]]), 400)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T09:55:43.309154Z","iopub.execute_input":"2024-08-02T09:55:43.309600Z","iopub.status.idle":"2024-08-02T09:56:07.792966Z","shell.execute_reply.started":"2024-08-02T09:55:43.309558Z","shell.execute_reply":"2024-08-02T09:56:07.791441Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"torch.Size([1, 1252, 80])\nBUT MISSUS RACHEL LYNDE WAS ONE OF THOSE CAPABLE CREATURES WHO CAN MANAGE THEIR OWN CONCERNS AND THOSE OF OTHER FOLKS INTO THE BARGAIN SHE WAS A NOTABLE HOUSEWIFE HER WORK WAS ALWAYS DONE AND WELL DONE SHE RAN THE SEWING CIRCLE\n","output_type":"stream"},{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"'but was his richard linen was one of those king both creatures who could manage their own concerns and those of other folks into the bargain she was an involunced with an invaltast wife her work was always long and and well thum she she was always longed on the and and well thom she he writed by them at this long circle'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}